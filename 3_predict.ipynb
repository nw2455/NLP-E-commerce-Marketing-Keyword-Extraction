{"cells":[{"cell_type":"markdown","metadata":{"id":"Mn28vKs6Gl_T"},"source":["# 0. Set Up\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"6nJbUeWxT6Th","outputId":"f7699b7e-f8f3-4529-910c-2c01e3b41b4e","executionInfo":{"status":"ok","timestamp":1639671458076,"user_tz":300,"elapsed":17413,"user":{"displayName":"Nicole Neo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibhk6m1I81GhGVy30Jr5tYt8JbIA1nTXILGnf4=s64","userId":"14518633936723975037"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pandas==1.3.4\n","  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n","\u001b[K     |████████████████████████████████| 11.3 MB 8.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4) (2018.9)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.15.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.1.5\n","    Uninstalling pandas-1.1.5:\n","      Successfully uninstalled pandas-1.1.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.4 which is incompatible.\u001b[0m\n","Successfully installed pandas-1.3.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pandas"]}}},"metadata":{}}],"source":["# Upgrade pandas to latest version as pickle objects were saved in latest pandas version\n","!pip install  pandas==1.3.4"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"BYubsnQMGgT6","executionInfo":{"status":"ok","timestamp":1639671517921,"user_tz":300,"elapsed":154,"user":{"displayName":"Nicole Neo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibhk6m1I81GhGVy30Jr5tYt8JbIA1nTXILGnf4=s64","userId":"14518633936723975037"}}},"outputs":[],"source":["# Import required modules\n","import pandas as pd\n","import numpy as np\n","import pickle"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JpFsMadATgbh","outputId":"62c1510d-a52e-48bc-b981-cefbb7b331b5","executionInfo":{"status":"ok","timestamp":1639671533347,"user_tz":300,"elapsed":13541,"user":{"displayName":"Nicole Neo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibhk6m1I81GhGVy30Jr5tYt8JbIA1nTXILGnf4=s64","userId":"14518633936723975037"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive to access files\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2377aabe-9b48-435f-bab6-22b18c9d566d","executionInfo":{"status":"ok","timestamp":1639671534614,"user_tz":300,"elapsed":143,"user":{"displayName":"Nicole Neo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibhk6m1I81GhGVy30Jr5tYt8JbIA1nTXILGnf4=s64","userId":"14518633936723975037"}},"id":"VIJ-JhaxBIQI"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/GR5067 NLP Project/data\n"]}],"source":["# Set directory\n","%cd /content/drive/My Drive/GR5067 NLP Project/data/"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"VsxU1yRCGukb","executionInfo":{"status":"ok","timestamp":1639671629159,"user_tz":300,"elapsed":27890,"user":{"displayName":"Nicole Neo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibhk6m1I81GhGVy30Jr5tYt8JbIA1nTXILGnf4=s64","userId":"14518633936723975037"}}},"outputs":[],"source":["# Import data\n","data_pet = pickle.load(open('Data Cleaning/data_pet.pkl', 'rb'))\n","data_countvec =  pickle.load(open('Vectorization/my_vec_data_1_1.pkl', 'rb'))\n","data_tfidf = pickle.load(open('Vectorization/my_tf_idf_data_1_1.pkl', 'rb'))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q6RJuWGrP6oW","outputId":"5c27f968-3650-48fd-9f5f-fec01aa3d1b8","executionInfo":{"status":"ok","timestamp":1639671632252,"user_tz":300,"elapsed":3096,"user":{"displayName":"Nicole Neo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibhk6m1I81GhGVy30Jr5tYt8JbIA1nTXILGnf4=s64","userId":"14518633936723975037"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(8756, 9563) (2919, 9563) (8756, 9563) (2919, 9563) \n"," (8756,) (2919,) (8756,) (2919,)\n"]}],"source":["# Splitting data into train and test set\n","from sklearn.model_selection import train_test_split\n","y = data_pet.pro_sales_num\n","X_c = data_countvec\n","X_t = data_tfidf\n","X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y, random_state=0)\n","X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_t, y, random_state=1)\n","print(X_train_c.shape, X_test_c.shape, X_train_t.shape, X_test_t.shape, '\\n',\n","      y_train_c.shape, y_test_c.shape, y_train_t.shape, y_test_t.shape)"]},{"cell_type":"markdown","metadata":{"id":"gcxXYIn5e4cn"},"source":["# 1. LinearRegression Model"]},{"cell_type":"markdown","metadata":{"id":"QCN1sm1re82f"},"source":["## 1.1 Training using CountVectorizer data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QGBOq9xMts6","outputId":"277ba7c1-66b5-4510-b995-9e40e8837441"},"outputs":[{"name":"stdout","output_type":"stream","text":["LINEAR REGRESSION (CountVectorizer data)\n","Training set score: 0.998\n","Test set score: -3861608762896474963968.000\n","Mean k-fold CV score: -2346653148224874348544.000\n"]}],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import cross_val_score\n","lr = LinearRegression().fit(X_train_c, y_train_c) \n","\n","print(\"LINEAR REGRESSION (CountVectorizer data)\")\n","print(\"Mean k-fold CV score: {:.3f}\".format(np.mean(cross_val_score(lr, X_train_c, y_train_c)))) # default scorer is r2\n","print(\"Training set score: {:.3f}\".format(lr.score(X_train_c, y_train_c))) \n","print(\"Test set score: {:.3f}\".format(lr.score(X_test_c, y_test_c)))"]},{"cell_type":"markdown","metadata":{"id":"7OaPGwkHfD-y"},"source":["## 1.2 Training using TF-IDF data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4_lZVg1e17-","outputId":"009d6b2a-8069-440f-c356-c73afee84717"},"outputs":[{"name":"stdout","output_type":"stream","text":["LINEAR REGRESSION (TF-IDF data)\n","Training set score: 0.996\n","Test set score: -2674059826798730240065536.000\n","Mean k-fold CV score: -1544445352530982800982016.000\n"]}],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import cross_val_score\n","lr = LinearRegression().fit(X_train_t, y_train_t) \n","\n","print(\"LINEAR REGRESSION (TF-IDF data)\")\n","print(\"Mean k-fold CV score: {:.3f}\".format(np.mean(cross_val_score(lr, X_train_t, y_train_t))))\n","print(\"Training set score: {:.3f}\".format(lr.score(X_train_t, y_train_t)))\n","print(\"Test set score: {:.3f}\".format(lr.score(X_test_t, y_test_t)))"]},{"cell_type":"markdown","metadata":{"id":"DGoFCBYohY2q"},"source":["<u> Interpreting results </u>    \n","From the results above, given a very high training set score and a very low (negative) test set score for both types of data, it is clear that the Linear Regression model is heavily overfitting on the training data. Hence there is a need to explore the use of **regularization** (e.g. Lasso regression) to restrict the model and prevent overfitting.\n","\n","Comparing CountVectorizer data to TF-IDF data, the model that is trained on TF-IDF data has a slightly better R-squared score. Hence, **TF-IDF data should be used instead of CountVectorized data** in our model to predict product sales volume using product names.\n","\n","<br>\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"i9yqcLaPfY4y"},"source":["# 2. Ridge Regression Model"]},{"cell_type":"markdown","metadata":{"id":"KaUWSrvJfgI_"},"source":["## 2.1 Training using CountVectorizer data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEno3E37fgJC","outputId":"26c0a6f9-d744-4f12-e1e9-723f49b3c7d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["RIDGE REGRESSION (CountVectorizer data)\n","Best mean CV score: 0.413\n","Best parameters: {'alpha': 1}\n","Training set score: 0.889\n","Test Set Score: 0.554\n"]}],"source":["from sklearn.linear_model import Ridge\n","from sklearn.model_selection import GridSearchCV\n","ridge_param_grid = {'alpha':[0.01, 0.1, 1, 10]} \n","ridge_grid = GridSearchCV(Ridge(random_state=2), param_grid=ridge_param_grid) \n","ridge_grid.fit(X_train_c, y_train_c)\n","\n","print(\"RIDGE REGRESSION (CountVectorizer data)\")\n","print(\"Best mean CV score: {:.3f}\".format(ridge_grid.best_score_))\n","print(\"Best parameters: {}\".format(ridge_grid.best_params_))\n","print(\"Training set score: {:.3f}\".format(ridge_grid.score(X_train_c, y_train_c)))\n","print(\"Test Set Score: {:.3f}\".format(ridge_grid.score(X_test_c, y_test_c)))"]},{"cell_type":"markdown","metadata":{"id":"DPJfVmaig_tn"},"source":["## 2.2 Training using TF-IDF data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtnwAiO9g_tw","outputId":"bebb3c66-2a6c-4d60-9714-097144e47486"},"outputs":[{"name":"stdout","output_type":"stream","text":["RIDGE REGRESSION (CountVectorizer data)\n","Best mean CV score: 0.428\n","Best parameters: {'alpha': 0.1}\n","Training set score: 0.922\n","Test Set Score: 0.707\n"]}],"source":["from sklearn.linear_model import Ridge\n","from sklearn.model_selection import GridSearchCV\n","ridge_param_grid = {'alpha':[0.01, 0.1, 1, 10]} \n","ridge_grid = GridSearchCV(Ridge(random_state=3), param_grid=ridge_param_grid) \n","ridge_grid.fit(X_train_t, y_train_t)\n","\n","print(\"RIDGE REGRESSION (CountVectorizer data)\")\n","print(\"Best mean CV score: {:.3f}\".format(ridge_grid.best_score_))\n","print(\"Best parameters: {}\".format(ridge_grid.best_params_))\n","print(\"Training set score: {:.3f}\".format(ridge_grid.score(X_train_t, y_train_t)))\n","print(\"Test Set Score: {:.3f}\".format(ridge_grid.score(X_test_t, y_test_t)))"]},{"cell_type":"markdown","metadata":{"id":"lf_wTZhawz9A"},"source":["<u> Interpreting results </u>    \n","From the results above, we can see that **Ridge Regression has overall much better performance that Linear Regression** since the test set scores are positive and much higher for Ridge regression. For CountVectorizer data, the test set score is 0.554 and for TF-IDF data, the test set score is even higher at 0.707. Nonetheless, as the test score is still lower than the training set score (0.922), **there could be overfitting** using this model and alternative models should still be explored.\n","\n","<br>\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"yXTObXULA7NL"},"source":["# 3. Lasso Regression Model"]},{"cell_type":"markdown","metadata":{"id":"G6zVPpWZA7NL"},"source":["## 3.1 Training using CountVectorizer data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"26c0a6f9-d744-4f12-e1e9-723f49b3c7d7","id":"UbSo41OyA7NL"},"outputs":[{"name":"stdout","output_type":"stream","text":["LASSO REGRESSION (CountVectorizer data)\n","Best mean CV score: 0.376\n","Best parameters: {'alpha': 0.1}\n","Training set score: 0.799\n","Test Set Score: 0.510\n"]}],"source":["from sklearn.linear_model import Lasso\n","from sklearn.model_selection import GridSearchCV\n","lasso_param_grid = {'alpha':[0.01, 0.1, 1, 10]} \n","lasso_grid = GridSearchCV(Lasso(max_iter=100000, random_state=4), param_grid=lasso_param_grid) \n","lasso_grid.fit(X_train_c, y_train_c)\n","\n","print(\"LASSO REGRESSION (CountVectorizer data)\")\n","print(\"Best mean CV score: {:.3f}\".format(lasso_grid.best_score_))\n","print(\"Best parameters: {}\".format(lasso_grid.best_params_))\n","print(\"Training set score: {:.3f}\".format(lasso_grid.score(X_train_c, y_train_c)))\n","print(\"Test Set Score: {:.3f}\".format(lasso_grid.score(X_test_c, y_test_c)))"]},{"cell_type":"markdown","metadata":{"id":"HqXt0qpRA7NM"},"source":["## 3.2 Training using TF-IDF data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lm1c-yGMA7NM"},"outputs":[],"source":["from sklearn.linear_model import Lasso\n","from sklearn.model_selection import GridSearchCV\n","lasso_param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10]} \n","lasso_grid = GridSearchCV(Lasso(max_iter=100000, random_state=5), param_grid=lasso_param_grid) \n","lasso_grid.fit(X_train_t, y_train_t)\n","\n","print(\"LASSO REGRESSION (TF-IDF data)\")\n","print(\"Best mean CV score: {:.3f}\".format(lasso_grid.best_score_))\n","print(\"Best parameters: {}\".format(lasso_grid.best_params_))\n","print(\"Training set score: {:.3f}\".format(lasso_grid.score(X_train_t, y_train_t)))\n","print(\"Test set Score: {:.3f}\".format(lasso_grid.score(X_test_t, y_test_t)))"]},{"cell_type":"markdown","metadata":{"id":"kG8X08PXA7NM"},"source":["<u> Interpreting results </u>    \n","From the results above, we can see that **Lasso Regression has comparable performance to Ridge Regression** since the test set scores are around the same range. For CountVectorizer data, the test score on Lasso at 0.510 is lower than that of Ridge (0.554). However for TF-IDF data, the test score on Lasso is higher at 0.735 compared to Ridge (0.707). Nonetheless, as this test score is still lower than the training set score of 0.913, **there could be overfitting** using this model and alternative models should still be explored.\n","\n","<br>\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"SpDNdthkIJ7j"},"source":["# 4. Random Forest Model\n"]},{"cell_type":"markdown","metadata":{"id":"O7jBwGIpSwQu"},"source":["## 4.1 Training using CountVectorizer data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBKY4IOiIJ7k","outputId":"715e2c1d-bcb9-4369-a676-20973fc7fb58"},"outputs":[{"name":"stdout","output_type":"stream","text":["RANDOM FOREST REGRESSION (CountVectorizer data)\n","Best mean CV score: 0.443\n","Best parameters: {'max_depth': 30, 'max_features': 'sqrt', 'n_estimators': 200, 'n_jobs': -1}\n","Training set score: 0.696\n","Test set Score: 0.536\n"]}],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import GridSearchCV\n","rfr_param_grid = {'n_estimators': [100, 200],\n","                  'max_depth': [10, 20, 30],\n","                  'max_features': ['log2', 'sqrt'],\n","                  'n_jobs': [-1]} \n","rfr_grid = GridSearchCV(RandomForestRegressor(random_state=6), param_grid=rfr_param_grid)\n","rfr_grid.fit(X_train_c, y_train_c)\n","\n","print(\"RANDOM FOREST REGRESSION (CountVectorizer data)\")\n","print(\"Best mean CV score: {:.3f}\".format(rfr_grid.best_score_))\n","print(\"Best parameters: {}\".format(rfr_grid.best_params_))\n","print(\"Training set score: {:.3f}\".format(rfr_grid.score(X_train_c, y_train_c)))\n","print(\"Test set Score: {:.3f}\".format(rfr_grid.score(X_test_c, y_test_c)))"]},{"cell_type":"markdown","metadata":{"id":"I8IxsZ7mUKNi"},"source":["## 4.2 Training using TF-IDF data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kaDKDmmTdQf","outputId":"2e802e00-fb2b-432d-9dcf-07f95cf7411a"},"outputs":[{"name":"stdout","output_type":"stream","text":["RANDOM FOREST REGRESSION (TD-IDF data)\n","Best mean CV score: 0.434\n","Best parameters: {'max_depth': 30, 'max_features': 'sqrt', 'n_estimators': 200, 'n_jobs': -1}\n","Training set score: 0.731\n","Test set Score: 0.583\n"]}],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import GridSearchCV\n","rfr_param_grid = {'n_estimators': [100, 200],\n","                  'max_depth': [10, 20, 30],\n","                  'max_features': ['log2', 'sqrt'],\n","                  'n_jobs': [-1]} \n","rfr_grid = GridSearchCV(RandomForestRegressor(random_state=7), param_grid=rfr_param_grid)\n","rfr_grid.fit(X_train_t, y_train_t)\n","\n","print(\"RANDOM FOREST REGRESSION (TD-IDF data)\")\n","print(\"Best mean CV score: {:.3f}\".format(rfr_grid.best_score_))\n","print(\"Best parameters: {}\".format(rfr_grid.best_params_))\n","print(\"Training set score: {:.3f}\".format(rfr_grid.score(X_train_t, y_train_t)))\n","print(\"Test set Score: {:.3f}\".format(rfr_grid.score(X_test_t, y_test_t)))"]},{"cell_type":"markdown","metadata":{"id":"j8YaF2_pA7NO"},"source":["<u> Interpreting results </u>    \n","From the results above, we can see that **Random Forest Regression has poorer performance relative to our previously best-performing models above**. For CountVectorizer data, the test score on Random Forest at 0.536 is lower than that of Ridge (0.554). For TF-IDF data, the test score on Random Forest at 0.583 is also lower compared to Lasso (0.735). For Random Forest, **there could also be overfitting** as the training set score at 0.731 is higher than the test set score of 0.583. Hence overall, Lasso Regression should still be preferred to Random Forest Regression.\n","\n","<br>\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"9sk4lY3G9r9I"},"source":["# 5. Model Selection and Evaluation"]},{"cell_type":"markdown","source":["## 5.1 Model Selection"],"metadata":{"id":"gABcSSh1DET7"}},{"cell_type":"markdown","metadata":{"id":"JKzKM8_CJd36"},"source":["To select the best model to predict sales volume based on product titles, we will choose the model with the highest test set score as this score represents the model's ability to generalize to new unseen data. We will also consider the model's training set score to see if there could be any overfitting or underfitting present.\n","\n","Among the models above, the best-performing model on the test set was the **Lasso Regression** model using  TF-IDF Vectorizer with a test set score of 0.735. This model also has the second smallest difference in training and test score at 0.913-0.735=0.14=0.178, making it reasonably less susceptible to overfitting than the other models. \n","\n","While Random Forest had the smallest difference in training and test score at 0.731-0.583=0.148, its test performance is significantly lower than Lasso Regression. We have only used a limited set of parameters to tune the Random Forest Regression model (e.g. using fewer `n_estimators` and only choosing between 'sqrt' and 'log2' for `max_features`) due to computational limitations, but we acknowledge that with more computational resources and time, we could possibly tune this model sufficiently to produce better test performance. Nonetheless based on our output with the current resources, we will still choose Lasso Regression as our best model as it has the best balance between test set performance and overfitting."]},{"cell_type":"code","source":["# Export best-performing model\n","pickle.dump(lasso_grid, open('Modelling/bestmodel_lasso.pkl', 'wb'))"],"metadata":{"id":"-PdOd-PtC-qc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Import best-performing model\n","# lasso_grid = pickle.load(open('Modelling/bestmodel_lasso.pkl', 'rb'))"],"metadata":{"id":"bSld2DdrDNeQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Lfyg87H9xwX"},"source":["## 5.2 Interpreting Lasso Model"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"JOzHc431A7NO"},"outputs":[],"source":["# Extracting Lasso coefficients into pandas dataframe\n","d = {'coef': lasso_grid.best_estimator_.coef_}\n","coefficients = pd.DataFrame(data=d, index=X_train_t.columns) \n","coefficients = coefficients.sort_values(['coef'], ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjbz83pzA7NP","outputId":"40aed05c-11a0-481c-f37c-a83fed7d1706"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>coef</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>粘狗</th>\n","      <td>16042.117798</td>\n","    </tr>\n","    <tr>\n","      <th>干无盐</th>\n","      <td>10896.410174</td>\n","    </tr>\n","    <tr>\n","      <th>ststtstst</th>\n","      <td>9335.263959</td>\n","    </tr>\n","    <tr>\n","      <th>多种</th>\n","      <td>9004.675974</td>\n","    </tr>\n","    <tr>\n","      <th>宠盒</th>\n","      <td>8895.959781</td>\n","    </tr>\n","    <tr>\n","      <th>品特</th>\n","      <td>8514.601694</td>\n","    </tr>\n","    <tr>\n","      <th>内特</th>\n","      <td>8507.977667</td>\n","    </tr>\n","    <tr>\n","      <th>包邮</th>\n","      <td>8387.789171</td>\n","    </tr>\n","    <tr>\n","      <th>梳柯</th>\n","      <td>7070.127679</td>\n","    </tr>\n","    <tr>\n","      <th>指挥棒</th>\n","      <td>7062.761661</td>\n","    </tr>\n","    <tr>\n","      <th>标准</th>\n","      <td>6823.537393</td>\n","    </tr>\n","    <tr>\n","      <th>多肉</th>\n","      <td>5675.140141</td>\n","    </tr>\n","    <tr>\n","      <th>亮丝</th>\n","      <td>5474.499360</td>\n","    </tr>\n","    <tr>\n","      <th>下沉</th>\n","      <td>5250.405471</td>\n","    </tr>\n","    <tr>\n","      <th>抽纸</th>\n","      <td>5101.223037</td>\n","    </tr>\n","    <tr>\n","      <th>darrenpet</th>\n","      <td>5099.726573</td>\n","    </tr>\n","    <tr>\n","      <th>器漏</th>\n","      <td>4775.176777</td>\n","    </tr>\n","    <tr>\n","      <th>葡萄球菌</th>\n","      <td>4718.975035</td>\n","    </tr>\n","    <tr>\n","      <th>摩擦</th>\n","      <td>4214.071165</td>\n","    </tr>\n","    <tr>\n","      <th>粮巴哥</th>\n","      <td>4054.252511</td>\n","    </tr>\n","    <tr>\n","      <th>味成</th>\n","      <td>3945.934236</td>\n","    </tr>\n","    <tr>\n","      <th>麦德豪</th>\n","      <td>3921.182881</td>\n","    </tr>\n","    <tr>\n","      <th>冬夏</th>\n","      <td>3849.320149</td>\n","    </tr>\n","    <tr>\n","      <th>佩玛思特</th>\n","      <td>3822.532581</td>\n","    </tr>\n","    <tr>\n","      <th>fw</th>\n","      <td>3782.869252</td>\n","    </tr>\n","    <tr>\n","      <th>fcyxzs</th>\n","      <td>3632.681859</td>\n","    </tr>\n","    <tr>\n","      <th>密梳</th>\n","      <td>3574.905810</td>\n","    </tr>\n","    <tr>\n","      <th>冰淇淋</th>\n","      <td>3283.247276</td>\n","    </tr>\n","    <tr>\n","      <th>机器猫</th>\n","      <td>3226.891039</td>\n","    </tr>\n","    <tr>\n","      <th>送瓶</th>\n","      <td>3173.769463</td>\n","    </tr>\n","    <tr>\n","      <th>尤克狗</th>\n","      <td>3041.720850</td>\n","    </tr>\n","    <tr>\n","      <th>鸟粮</th>\n","      <td>2987.622790</td>\n","    </tr>\n","    <tr>\n","      <th>泰迪带</th>\n","      <td>2943.754488</td>\n","    </tr>\n","    <tr>\n","      <th>liyu</th>\n","      <td>2868.257602</td>\n","    </tr>\n","    <tr>\n","      <th>水器</th>\n","      <td>2770.621584</td>\n","    </tr>\n","    <tr>\n","      <th>踏脚板</th>\n","      <td>2713.307197</td>\n","    </tr>\n","    <tr>\n","      <th>秋田</th>\n","      <td>2709.523793</td>\n","    </tr>\n","    <tr>\n","      <th>mbm</th>\n","      <td>2640.933475</td>\n","    </tr>\n","    <tr>\n","      <th>躲藏</th>\n","      <td>2638.876282</td>\n","    </tr>\n","    <tr>\n","      <th>警示灯</th>\n","      <td>2635.245448</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   coef\n","粘狗         16042.117798\n","干无盐        10896.410174\n","ststtstst   9335.263959\n","多种          9004.675974\n","宠盒          8895.959781\n","品特          8514.601694\n","内特          8507.977667\n","包邮          8387.789171\n","梳柯          7070.127679\n","指挥棒         7062.761661\n","标准          6823.537393\n","多肉          5675.140141\n","亮丝          5474.499360\n","下沉          5250.405471\n","抽纸          5101.223037\n","darrenpet   5099.726573\n","器漏          4775.176777\n","葡萄球菌        4718.975035\n","摩擦          4214.071165\n","粮巴哥         4054.252511\n","味成          3945.934236\n","麦德豪         3921.182881\n","冬夏          3849.320149\n","佩玛思特        3822.532581\n","fw          3782.869252\n","fcyxzs      3632.681859\n","密梳          3574.905810\n","冰淇淋         3283.247276\n","机器猫         3226.891039\n","送瓶          3173.769463\n","尤克狗         3041.720850\n","鸟粮          2987.622790\n","泰迪带         2943.754488\n","liyu        2868.257602\n","水器          2770.621584\n","踏脚板         2713.307197\n","秋田          2709.523793\n","mbm         2640.933475\n","躲藏          2638.876282\n","警示灯         2635.245448"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["# Creating dataframe of top 40 coefficients\n","coefficients_top40 = coefficients.head(40)\n","coefficients_top40"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySVVDOytA7NP"},"outputs":[],"source":["# Exporting dataframe of top 40 coefficients\n","coefficients_top40.to_csv(path + 'coefficients_top40.csv', index=True)"]},{"cell_type":"markdown","source":["## 5.3 Using Lasso Model to predict new data"],"metadata":{"id":"X9G7GpwMDnHG"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"3_predict.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}